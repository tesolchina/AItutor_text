<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Audio Tutor UI</title>
    <style>
        body { 
            font-family: Arial, sans-serif; 
            text-align: center; 
            margin: 0; 
            padding: 20px;
            background-color: #f0f2f5;
            color: #333;
        }
        
        #chat-container {
            width: 90%;
            max-width: 600px;
            height: 400px;
            margin: 20px auto;
            border: 1px solid #ddd;
            border-radius: 10px;
            background: white;
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }
        
        #transcript {
            flex-grow: 1;
            overflow-y: auto;
            padding: 15px;
            text-align: left;
            display: flex;
            flex-direction: column;
        }
        
        /* WeChat-style message bubbles */
        .message-row {
            margin-bottom: 15px;
            display: flex;
            flex-direction: column;
            max-width: 80%;
        }
        
        .user-row {
            align-self: flex-end;
        }
        
        .tutor-row {
            align-self: flex-start;
        }
        
        .message-bubble {
            padding: 10px 15px;
            border-radius: 18px;
            margin-bottom: 5px;
            position: relative;
            word-wrap: break-word;
            line-height: 1.4;
        }
        
        .user-bubble {
            background-color: #95ec69;
            border-top-right-radius: 3px;
        }
        
        .tutor-bubble {
            background-color: #ffffff;
            border: 1px solid #e0e0e0;
            border-top-left-radius: 3px;
        }
        
        .message-meta {
            font-size: 11px;
            color: #999;
            margin-top: 2px;
            padding: 0 5px;
        }
        
        /* Avatar container */
        #avatar-container {
            position: relative;
            height: 150px;
            margin: 0 auto 20px auto;
        }
        
        #owl-icon {
            font-size: 100px;
            position: relative;
            z-index: 10;
        }
        
        /* Animation states */
        .owl-idle {
            animation: gentle-float 3s infinite ease-in-out;
        }
        
        .owl-listening {
            animation: gentle-float 3s infinite ease-in-out;
        }
        
        .owl-thinking {
            animation: thinking 1s infinite ease-in-out;
        }
        
        .owl-speaking {
            animation: bounce 0.8s infinite;
        }
        
        /* Status indicator */
        #status-indicator {
            position: absolute;
            bottom: -10px;
            left: 50%;
            transform: translateX(-50%);
            font-size: 14px;
            background-color: rgba(0,0,0,0.7);
            color: white;
            padding: 5px 10px;
            border-radius: 15px;
            z-index: 20;
        }
        
        /* Sound waves (for listening) */
        .sound-waves {
            position: absolute;
            top: 40px;
            right: -15px;
            width: 30px;
            height: 30px;
            z-index: 5;
        }
        
        .wave {
            position: absolute;
            background: rgba(33, 150, 243, 0.3);
            border-radius: 50%;
            opacity: 0;
        }
        
        .wave-1 {
            width: 20px;
            height: 20px;
            animation: wave 2s infinite ease-out;
        }
        
        .wave-2 {
            width: 30px;
            height: 30px;
            animation: wave 2s infinite 0.5s ease-out;
        }
        
        .wave-3 {
            width: 40px;
            height: 40px;
            animation: wave 2s infinite 1s ease-out;
        }
        
        /* Thinking animation (dots) */
        .thinking-dots {
            position: absolute;
            left: 70px;
            top: 30px;
            display: none;
            z-index: 5;
        }
        
        .dot {
            display: inline-block;
            width: 8px;
            height: 8px;
            background-color: #333;
            border-radius: 50%;
            margin: 0 2px;
        }
        
        .dot-1 { animation: blink 1.4s infinite 0.2s; }
        .dot-2 { animation: blink 1.4s infinite 0.4s; }
        .dot-3 { animation: blink 1.4s infinite 0.6s; }
        
        /* Control buttons */
        #bottom-controls {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            justify-content: center;
            gap: 15px;
        }
        
        button {
            padding: 12px 24px;
            font-size: 16px;
            border-radius: 30px;
            border: none;
            cursor: pointer;
            transition: all 0.2s;
            font-weight: bold;
            box-shadow: 0 2px 5px rgba(0,0,0,0.2);
        }
        
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
        }
        
        button:active {
            transform: translateY(1px);
            box-shadow: 0 1px 3px rgba(0,0,0,0.2);
        }
        
        #startBtn {
            background-color: #2196F3;
            color: white;
        }
        
        #stopTalkingBtn {
            background-color: #F44336;
            color: white;
            display: none;
        }
        
        #stopSpeakingBtn {
            background-color: #FF9800;
            color: white;
        }
        
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }
        
        /* Animations */
        @keyframes bounce {
            0%, 100% { transform: translateY(0); }
            50% { transform: translateY(-10px); }
        }
        
        @keyframes gentle-float {
            0%, 100% { transform: translateY(0); }
            50% { transform: translateY(-5px); }
        }
        
        @keyframes thinking {
            0%, 100% { transform: rotate(-5deg); }
            50% { transform: rotate(5deg); }
        }
        
        @keyframes wave {
            0% { transform: scale(0.5); opacity: 0.5; }
            100% { transform: scale(1.5); opacity: 0; }
        }
        
        @keyframes blink {
            0%, 100% { opacity: 0.2; }
            50% { opacity: 1; }
        }
    </style>
</head>
<body>
    <h1>English Tutor Chat</h1>
    
    <div id="avatar-container">
        <div id="owl-icon" class="owl-idle">ðŸ¦‰</div>
        <div id="status-indicator">Idle</div>
        
        <!-- Sound waves (for listening) -->
        <div class="sound-waves">
            <div class="wave wave-1"></div>
            <div class="wave wave-2"></div>
            <div class="wave wave-3"></div>
        </div>
        
        <!-- Thinking animation -->
        <div class="thinking-dots">
            <span class="dot dot-1"></span>
            <span class="dot dot-2"></span>
            <span class="dot dot-3"></span>
        </div>
    </div>
    
    <div id="chat-container">
        <div id="transcript"></div>
    </div>
    
    <div id="bottom-controls">
        <button id="startBtn">Start Talking</button>
        <button id="stopTalkingBtn">Stop Talking</button>
        <button id="stopSpeakingBtn" disabled>Stop Tutor Speaking</button>
    </div>
    
    <script>
        const startBtn = document.getElementById('startBtn');
        const stopTalkingBtn = document.getElementById('stopTalkingBtn');
        const stopSpeakingBtn = document.getElementById('stopSpeakingBtn');
        const transcriptArea = document.getElementById('transcript');
        const owlIcon = document.getElementById('owl-icon');
        const statusIndicator = document.getElementById('status-indicator');
        const soundWaves = document.querySelector('.sound-waves');
        const thinkingDots = document.querySelector('.thinking-dots');
        
        let recognition;
        let isListening = false;
        let isTutorSpeaking = false;
        let isProcessing = false;
        let startTime = 0;
        let timerInterval;
        
        // Initialize Web Speech Recognition (STT)
        if ('webkitSpeechRecognition' in window) {
            recognition = new webkitSpeechRecognition();
            recognition.continuous = true; // Keep listening until explicitly stopped
            recognition.interimResults = false;
            recognition.lang = 'en-US';
        } else {
            alert('Browser does not support speech recognition.');
        }
        
        // Set owl state and animation
        function setOwlState(state) {
            // Remove all state classes
            owlIcon.classList.remove('owl-idle', 'owl-listening', 'owl-thinking', 'owl-speaking');
            
            // Hide all state indicators
            soundWaves.style.display = 'none';
            thinkingDots.style.display = 'none';
            
            // Set new state
            switch(state) {
                case 'idle':
                    owlIcon.classList.add('owl-idle');
                    statusIndicator.textContent = 'Idle';
                    break;
                case 'listening':
                    owlIcon.classList.add('owl-listening');
                    soundWaves.style.display = 'block';
                    statusIndicator.textContent = 'Listening...';
                    break;
                case 'thinking':
                    owlIcon.classList.add('owl-thinking');
                    thinkingDots.style.display = 'block';
                    statusIndicator.textContent = 'Thinking...';
                    break;
                case 'speaking':
                    owlIcon.classList.add('owl-speaking');
                    statusIndicator.textContent = 'Speaking...';
                    break;
            }
        }
        
        // Start listening function
        function startListening() {
            if (!isListening && !isProcessing) {
                try {
                    recognition.start();
                    startBtn.style.display = 'none';
                    stopTalkingBtn.style.display = 'inline-block';
                    isListening = true;
                    
                    // Change owl state
                    setOwlState('listening');
                    
                    // Start the timer
                    startTime = Date.now();
                } catch (error) {
                    console.error("Recognition error:", error);
                    // If already started, stop and restart
                    recognition.stop();
                    setTimeout(() => {
                        startListening();
                    }, 200);
                }
            }
        }
        
        // Stop listening function and process input
        function stopListening() {
            if (isListening) {
                recognition.stop();
                stopTalkingBtn.style.display = 'none';
                startBtn.style.display = 'inline-block';
                isListening = false;
                
                // Set state to thinking while processing
                isProcessing = true;
                setOwlState('thinking');
            }
        }
        
        // Function to count words in a string
        function countWords(str) {
            return str.trim().split(/\s+/).length;
        }
        
        // Button event listeners
        startBtn.addEventListener('click', startListening);
        stopTalkingBtn.addEventListener('click', () => {
            stopListening();
            // Use the last result from recognition
            processLastRecognitionResult();
        });
        
        // Process the last recognition result
        function processLastRecognitionResult() {
            const userInput = recognitionTranscript || "Sorry, I didn't catch that. Could you try again?";
            const duration = Math.round((Date.now() - startTime) / 1000);
            const wordCount = countWords(userInput);
            
            // Add user message to transcript
            addMessageToTranscript('You', userInput, true, duration, wordCount);
            
            // Clear for next input
            recognitionTranscript = '';
            
            // Get response from tutor
            getLLMResponse(userInput).then(llmResponse => {
                // Change state from thinking to speaking
                isProcessing = false;
                
                // Add tutor response to transcript
                const tutorWordCount = countWords(llmResponse);
                addMessageToTranscript('Tutor', llmResponse, false, 0, tutorWordCount);
                
                // Speak the response
                speakResponse(llmResponse);
            });
        }
        
        // Keep track of recognized speech
        let recognitionTranscript = '';
        
        // Recognition result handler - collect speech but don't process until stop button
        recognition.onresult = (event) => {
            const resultIndex = event.resultIndex;
            const transcript = event.results[resultIndex][0].transcript;
            recognitionTranscript = transcript;
        };
        
        recognition.onend = () => {
            // This ensures that if recognition ends unexpectedly, UI stays consistent
            // But DON'T process automatically - wait for the stop button
            if (isListening) {
                isListening = false;
                stopTalkingBtn.style.display = 'none';
                startBtn.style.display = 'inline-block';
                setOwlState('idle');
            }
        };
        
        // Function to add message to transcript with proper formatting
        function addMessageToTranscript(speaker, message, isUser, duration, wordCount) {
            const messageRow = document.createElement('div');
            messageRow.className = isUser ? 'message-row user-row' : 'message-row tutor-row';
            
            const messageBubble = document.createElement('div');
            messageBubble.className = isUser ? 'message-bubble user-bubble' : 'message-bubble tutor-bubble';
            messageBubble.textContent = message;
            
            const messageMeta = document.createElement('div');
            messageMeta.className = 'message-meta';
            
            // Add word count and duration (if available)
            let metaText = `${wordCount} words`;
            if (duration > 0) {
                metaText += ` â€¢ ${duration} seconds`;
            }
            messageMeta.textContent = metaText;
            
            messageRow.appendChild(messageBubble);
            messageRow.appendChild(messageMeta);
            transcriptArea.appendChild(messageRow);
            
            // Scroll to bottom
            transcriptArea.scrollTop = transcriptArea.scrollHeight;
        }
        
        // Function to call backend /chat endpoint
        async function getLLMResponse(input) {
            try {
                const response = await fetch('/chat', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ user_input: input })
                });
                const data = await response.json();
                return data.response || data.error;
            } catch (error) {
                console.error(error);
                return 'Sorry, there was an error processing your request.';
            }
        }
        
        // TTS using browser SpeechSynthesis
        function speakResponse(text) {
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'en-US';
            
            // Try to find a good voice
            const voices = speechSynthesis.getVoices();
            const preferredVoice = voices.find(voice => 
                voice.name.includes('Google') && voice.name.includes('Female')
            ) || voices.find(voice => 
                voice.name.includes('Google')
            ) || voices[0];
            
            if (preferredVoice) {
                utterance.voice = preferredVoice;
            }
            
            // Start tutor speaking animation
            setOwlState('speaking');
            stopSpeakingBtn.disabled = false;
            isTutorSpeaking = true;
            
            // Start timer for tutor
            startTime = Date.now();
            
            // Handle speech end
            utterance.onend = finishTutorSpeaking;
            
            speechSynthesis.speak(utterance);
        }
        
        // Function to handle end of tutor speaking
        function finishTutorSpeaking() {
            setOwlState('idle');
            stopSpeakingBtn.disabled = true;
            isTutorSpeaking = false;
            
            // Update the duration in the last tutor message
            const duration = Math.round((Date.now() - startTime) / 1000);
            const tutorMeta = transcriptArea.querySelector('.tutor-row:last-child .message-meta');
            if (tutorMeta) {
                const currentText = tutorMeta.textContent;
                tutorMeta.textContent = currentText + ` â€¢ ${duration} seconds`;
            }
        }
        
        // Stop speaking button
        stopSpeakingBtn.addEventListener('click', () => {
            speechSynthesis.cancel();
            finishTutorSpeaking();
        });
        
        // Initialize voices when they become available
        speechSynthesis.onvoiceschanged = () => {
            console.log("Voices loaded:", speechSynthesis.getVoices().length);
        };
        
        // Initialize owl to idle state
        setOwlState('idle');
    </script>
</body>
</html>